{
  "description": "var Component=(()=>{var l=Object.create;var s=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var u=Object.getOwnPropertyNames;var d=Object.getPrototypeOf,f=Object.prototype.hasOwnProperty;var y=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),g=(t,e)=>{for(var a in e)s(t,a,{get:e[a],enumerable:!0})},c=(t,e,a,r)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let i of u(e))!f.call(t,i)&&i!==a&&s(t,i,{get:()=>e[i],enumerable:!(r=p(e,i))||r.enumerable});return t};var w=(t,e,a)=>(a=t!=null?l(d(t)):{},c(e||!t||!t.__esModule?s(a,\"default\",{value:t,enumerable:!0}):a,t)),x=t=>c(s({},\"__esModule\",{value:!0}),t);var h=y((P,o)=>{o.exports=_jsx_runtime});var b={};g(b,{default:()=>j,frontmatter:()=>A});var n=w(h()),A={title:\"Map Async Limit\",excerpt:\"Implement a function that maps an array of items with an asynchronous mapping function while not exceeding the concurrency limit\"};function m(t){let e=Object.assign({p:\"p\",a:\"a\",code:\"code\",h2:\"h2\",pre:\"pre\"},t.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(e.p,{children:[\"In \",(0,n.jsx)(e.a,{href:\"/questions/javascript/map-async\",children:\"Map Async\"}),\", we wrote a function that accepts an array of items and maps each element with an asynchronous mapping function and returns a \",(0,n.jsx)(e.code,{children:\"Promise\"}),\" which resolves to the mapped results.\"]}),`\n`,(0,n.jsx)(e.p,{children:\"Practically, this can be used for mapping an input array with the results of calling an API where the input element is the argument to the API. However, if your array has a large amount of items, you'd be making that many API calls at the same time which will almost certainly get you rate limited by the API service. We want to execute our tasks concurrently so that it is more efficient, yet stay within the rate limits of the API.\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Implement a \",(0,n.jsx)(e.code,{children:\"mapAsyncLimit\"}),\" that takes in an optional parameter \",(0,n.jsx)(e.code,{children:\"size\"}),\", the maximum number of ongoing async tasks so that the input array can be processed in chunks of \",(0,n.jsx)(e.code,{children:\"size\"}),\", achieving parallelism and staying within the provided limit. If \",(0,n.jsx)(e.code,{children:\"size\"}),\" is not specified, the chunk size is unlimited.\"]}),`\n`,(0,n.jsx)(e.h2,{children:\"Examples\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-js\",children:`async function fetchUpperCase(q: string) {\n  // Fake API service that converts a string to uppercase.\n  const res = await fetch('https://uppercase.com?q=' + q);\n  return await res.text();\n}\n\n// Only a maximum of 2 pending requests at any one time.\nconst results = await mapAsyncLimit(\n  ['foo', 'bar', 'qux', 'quz'],\n  fetchUpperCase,\n  2,\n);\nconsole.log(results); // ['FOO', 'BAR', 'QUX', 'QUZ'];\n`})})]})}function I(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,Object.assign({},t,{children:(0,n.jsx)(m,t)})):m(t)}var j=I;return x(b);})();\n;return Component;",
  "files": {
    "/package.json": "{\n  \"name\": \"@gfe-questions/map-async-limit\",\n  \"version\": \"0.0.1\",\n  \"main\": \"/src/map-async-limit.ts\",\n  \"devDependencies\": {\n    \"@types/jest\": \"29.5.0\",\n    \"typescript\": \"5.0.2\"\n  }\n}\n",
    "/tsconfig.json": "{\n  \"include\": [\"./**/*\"],\n  \"compilerOptions\": {\n    \"strict\": true,\n    \"esModuleInterop\": true,\n    \"lib\": [\"dom\", \"dom.iterable\", \"esnext\"],\n    \"jsx\": \"react-jsx\",\n    \"target\": \"es2020\"\n  }\n}\n",
    "/src/map-async-limit.run.test.ts": "import mapAsyncLimit from './map-async-limit';\n\nconst asyncIdentity = (x: number) => Promise.resolve(x);\n\ndescribe('mapAsyncLimit', () => {\n  test('returns promise', () => {\n    const p = mapAsyncLimit([], asyncIdentity);\n    expect(p).toBeInstanceOf(Promise);\n  });\n\n  test('empty input array', async () => {\n    expect.assertions(1);\n    const res = await mapAsyncLimit([], asyncIdentity);\n    expect(res).toEqual([]);\n  });\n\n  test('resolved', async () => {\n    expect.assertions(1);\n    let ongoing = 0;\n    const limit = 2;\n\n    const res = await mapAsyncLimit(\n      [1, 2, 3, 4, 5],\n      (x: number) => {\n        ongoing++;\n        return new Promise((resolve, reject) => {\n          setTimeout(() => {\n            if (ongoing > limit) {\n              reject('Concurrency limit exceeded');\n            }\n\n            resolve(x * 2);\n            ongoing--;\n          }, 10);\n        });\n      },\n      limit,\n    );\n\n    expect(res).toEqual([2, 4, 6, 8, 10]);\n  });\n});\n",
    "/src/map-async-limit.submit.test.ts": "import mapAsyncLimit from './map-async-limit';\n\nconst asyncIdentity = (x: number) => Promise.resolve(x);\nconst asyncDouble = (x: number) =>\n  new Promise((resolve) => {\n    setTimeout(() => {\n      resolve(x * 2);\n    }, 10);\n  });\nconst asyncSquare = (x: number) =>\n  new Promise((resolve) => {\n    setTimeout(() => {\n      resolve(x * x);\n    }, 10);\n  });\nconst asyncRejectOdd = (x: number) =>\n  new Promise((resolve, reject) => {\n    setTimeout(() => {\n      if (x % 2 === 1) {\n        reject(x * 3);\n      }\n\n      resolve(x * 2);\n    }, 10);\n  });\n\ndescribe('mapAsyncLimit', () => {\n  test('returns promise', () => {\n    const p = mapAsyncLimit([], asyncIdentity);\n    expect(p).toBeInstanceOf(Promise);\n  });\n\n  test('empty input array', async () => {\n    expect.assertions(1);\n    const res = await mapAsyncLimit([], asyncIdentity);\n    expect(res).toEqual([]);\n  });\n\n  test('single item', async () => {\n    expect.assertions(1);\n    const res = await mapAsyncLimit([3], asyncDouble);\n    expect(res).toEqual([6]);\n  });\n\n  describe('multiple items', () => {\n    describe('no limit', () => {\n      test('all resolved', async () => {\n        expect.assertions(1);\n        const res = await mapAsyncLimit([2, 3, 4, 5, 6], asyncSquare);\n        expect(res).toEqual([4, 9, 16, 25, 36]);\n      });\n\n      test('some rejected', async () => {\n        expect.assertions(1);\n        await expect(mapAsyncLimit([2, 3], asyncRejectOdd)).rejects.toBe(9);\n      });\n    });\n\n    test('limit of one', async () => {\n      expect.assertions(1);\n      let ongoing = 0;\n      const limit = 1;\n\n      const res = await mapAsyncLimit(\n        [2, 3, 4, 5, 6],\n        (x: number) => {\n          ongoing++;\n          return new Promise((resolve, reject) => {\n            setTimeout(() => {\n              if (ongoing > limit) {\n                reject('Concurrency limit exceeded');\n              }\n\n              resolve(x * x);\n              ongoing--;\n            }, 10);\n          });\n        },\n        limit,\n      );\n\n      expect(res).toEqual([4, 9, 16, 25, 36]);\n    });\n\n    test('limit of two', async () => {\n      expect.assertions(1);\n      let ongoing = 0;\n      const limit = 2;\n\n      const res = await mapAsyncLimit(\n        [2, 3, 4, 5, 6],\n        (x: number) => {\n          ongoing++;\n          return new Promise((resolve, reject) => {\n            setTimeout(() => {\n              if (ongoing > limit) {\n                reject('Concurrency limit exceeded');\n              }\n\n              resolve(x * x);\n              ongoing--;\n            }, 10);\n          });\n        },\n        limit,\n      );\n\n      expect(res).toEqual([4, 9, 16, 25, 36]);\n    });\n\n    test('limit more than the input', async () => {\n      expect.assertions(1);\n      let ongoing = 0;\n      const limit = 10;\n\n      const res = await mapAsyncLimit(\n        [2, 3, 4, 5, 6],\n        (x: number) => {\n          ongoing++;\n          return new Promise((resolve, reject) => {\n            setTimeout(() => {\n              if (ongoing > limit) {\n                reject('Concurrency limit exceeded');\n              }\n\n              resolve(x * x);\n              ongoing--;\n            }, 10);\n          });\n        },\n        limit,\n      );\n\n      expect(res).toEqual([4, 9, 16, 25, 36]);\n    });\n  });\n});\n",
    "/src/map-async-limit.ts": "export default function mapAsyncLimit<T, U>(\n  iterable: Array<T>,\n  callbackFn: (value: T) => Promise<U>,\n  size: number = Infinity,\n): Promise<Array<U>> {\n  if (iterable.length === 0) {\n    return Promise.resolve([]);\n  }\n\n  return Promise.all(iterable.slice(0, size).map(callbackFn)).then((results) =>\n    mapAsyncLimit(iterable.slice(size), callbackFn, size).then((rest) => [\n      ...results,\n      ...rest,\n    ]),\n  );\n}\n"
  },
  "metadata": {
    "access": "standard",
    "author": null,
    "companies": [
      "google",
      "lyft",
      "uber",
      "apple",
      "tiktok",
      "bytedance"
    ],
    "created": 1699401600,
    "difficulty": "medium",
    "duration": 25,
    "excerpt": "Implement a function that maps an array of items with an asynchronous mapping function while not exceeding the concurrency limit",
    "featured": false,
    "format": "javascript",
    "frameworkDefault": null,
    "frameworks": [],
    "href": "/questions/javascript/map-async-limit",
    "importance": "low",
    "languages": [
      "js",
      "ts"
    ],
    "nextQuestions": [
      "middlewares"
    ],
    "published": true,
    "ranking": 100,
    "similarQuestions": [
      "promise-all"
    ],
    "slug": "map-async-limit",
    "subtitle": null,
    "title": "Map Async Limit",
    "topics": [
      "async"
    ]
  },
  "skeleton": {
    "js": "/**\n * @param {Array<any>} iterable\n * @param {Function} callbackFn\n * @param {number} size\n *\n * @return {Promise}\n */\nexport default function mapAsyncLimit(iterable, callbackFn, size) {\n  throw 'Not implemented';\n}",
    "ts": "export default function mapAsyncLimit<T, U>(\n  iterable: Array<T>,\n  callbackFn: (value: T) => Promise<U>,\n  size?: number,\n): Promise<Array<U>> {\n  throw 'Not implemented';\n}"
  },
  "solution": "var Component=(()=>{var x=Object.create;var a=Object.defineProperty;var g=Object.getOwnPropertyDescriptor;var w=Object.getOwnPropertyNames;var k=Object.getPrototypeOf,v=Object.prototype.hasOwnProperty;var A=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),I=(t,e)=>{for(var i in e)a(t,i,{get:e[i],enumerable:!0})},c=(t,e,i,l)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let s of w(e))!v.call(t,s)&&s!==i&&a(t,s,{get:()=>e[s],enumerable:!(l=g(e,s))||l.enumerable});return t};var T=(t,e,i)=>(i=t!=null?x(k(t)):{},c(e||!t||!t.__esModule?a(i,\"default\",{value:t,enumerable:!0}):i,t)),z=t=>c(a({},\"__esModule\",{value:!0}),t);var h=A((B,o)=>{o.exports=_jsx_runtime});var S={};I(S,{default:()=>M});var n=T(h());var r=MDXCodeBlock;var d=`export default function mapAsyncLimit<T, U>(\n  iterable: Array<T>,\n  callbackFn: (value: T) => Promise<U>,\n  size: number = Infinity,\n): Promise<Array<U>> {\n  return new Promise((resolve, reject) => {\n    const results: Array<U> = [];\n\n    function processItem(index: number) {\n      if (index === iterable.length) {\n        resolve(results);\n      }\n\n      return callbackFn(iterable[index])\n        .then((result) => {\n          results.push(result);\n          processItem(index + 1);\n        })\n        .catch(reject);\n    }\n\n    return processItem(0);\n  });\n}\n`;var m=`/**\n * @param {Array<any>} iterable\n * @param {Function} callbackFn\n * @param {number} size\n *\n * @return {Promise}\n */\nexport default function mapAsyncLimit(iterable, callbackFn, size = Infinity) {\n  if (iterable.length === 0) {\n    return Promise.resolve([]);\n  }\n\n  const currentChunk = iterable.slice(0, size);\n  const remainingItems = iterable.slice(size);\n\n  return Promise.all(currentChunk.map(callbackFn)).then((results) =>\n    mapAsyncLimit(remainingItems, callbackFn, size).then((rest) => [\n      ...results,\n      ...rest,\n    ]),\n  );\n}\n`;var u=`export default function mapAsyncLimit<T, U>(\n  iterable: Array<T>,\n  callbackFn: (value: T) => Promise<U>,\n  size: number = Infinity,\n): Promise<Array<U>> {\n  if (iterable.length === 0) {\n    return Promise.resolve([]);\n  }\n\n  return Promise.all(iterable.slice(0, size).map(callbackFn)).then((results) =>\n    mapAsyncLimit(iterable.slice(size), callbackFn, size).then((rest) => [\n      ...results,\n      ...rest,\n    ]),\n  );\n}\n`;var p=`export default async function mapAsyncLimit<T, U>(\n  iterable: Array<T>,\n  callbackFn: (value: T) => Promise<U>,\n  size: number = Infinity,\n): Promise<Array<U>> {\n  const results = [];\n\n  for (let i = 0; i < iterable.length; i += size) {\n    const chunk = iterable.slice(i, i + size);\n    const chunkResults = await Promise.all(chunk.map(callbackFn));\n\n    results.push(...chunkResults);\n  }\n\n  return results;\n}\n`;var f=`export default function mapAsyncLimit<T, U>(\n  iterable: Array<T>,\n  callbackFn: (value: T) => Promise<U>,\n  size: number = Infinity,\n): Promise<Array<U>> {\n  return new Promise((resolve, reject) => {\n    const results: Array<U> = [];\n    let nextIndex = 0;\n    let resolved = 0;\n\n    if (iterable.length === 0) {\n      resolve(results);\n      return;\n    }\n\n    function processItem(index: number) {\n      nextIndex++;\n      callbackFn(iterable[index])\n        .then((result) => {\n          results[index] = result;\n          resolved++;\n\n          if (resolved === iterable.length) {\n            resolve(results);\n            return;\n          }\n\n          if (nextIndex < iterable.length) {\n            processItem(nextIndex);\n          }\n        })\n        .catch(reject);\n    }\n\n    for (let i = 0; i < Math.min(iterable.length, size); i++) {\n      processItem(i);\n    }\n  });\n}\n`;var y=`export default function mapAsyncLimit<T, U>(\n  iterable: Array<T>,\n  callbackFn: (value: T) => Promise<U>,\n  size: number = Infinity,\n): Promise<Array<U>> {\n  return new Promise((resolve, reject) => {\n    const results: Array<U> = [];\n    let nextIndex = 0;\n    let resolved = 0;\n\n    if (iterable.length === 0) {\n      resolve(results);\n      return;\n    }\n\n    async function processItem(index: number) {\n      nextIndex++;\n      try {\n        const result = await callbackFn(iterable[index]);\n        results[index] = result;\n        resolved++;\n\n        if (resolved === iterable.length) {\n          resolve(results);\n          return;\n        }\n\n        if (nextIndex < iterable.length) {\n          processItem(nextIndex);\n        }\n      } catch (err) {\n        reject(err);\n      }\n    }\n\n    for (let i = 0; i < Math.min(iterable.length, size); i++) {\n      processItem(i);\n    }\n  });\n}\n`;function b(t){let e=Object.assign({h2:\"h2\",p:\"p\",code:\"code\",a:\"a\",h3:\"h3\",ol:\"ol\",li:\"li\",img:\"img\",ul:\"ul\",strong:\"strong\"},t.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.h2,{children:\"Solution\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"The general idea is to slice the input array into chunks of \",(0,n.jsx)(e.code,{children:\"size\"}),\" elements and processing one chunk at a time. The solutions presented here use \",(0,n.jsx)(e.code,{children:\"Promise.all\"}),\" but if it's not allowed, you can use the self-implemented versions presented in the \",(0,n.jsxs)(e.a,{href:\"/questions/javascript/promise-all\",children:[(0,n.jsx)(e.code,{children:\"Promise.all\"}),\" question\"]}),\".\"]}),`\n`,(0,n.jsx)(e.h3,{children:\"Approach 1: Sequential (Bad!)\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"This approach ignores the \",(0,n.jsx)(e.code,{children:\"size\"}),\" parameter and processes each item one-by-one. This is well within the concurrency limit, but defeats the purpose of the question.\"]}),`\n`,(0,n.jsx)(r,{children:d}),`\n`,(0,n.jsx)(e.h3,{children:\"Approach 2: Chunks with recursion\"}),`\n`,(0,n.jsx)(e.p,{children:\"Mapping an array of items in chunks can be broken down into smaller sub-problems and solved recursively:\"}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsxs)(e.li,{children:[\"Process items in the current chunk concurrently via \",(0,n.jsx)(e.code,{children:\"Promise.all\"}),\".\"]}),`\n`,(0,n.jsxs)(e.li,{children:[\"Recursively call \",(0,n.jsx)(e.code,{children:\"mapAsyncLimit\"}),\" on the remaining items.\"]}),`\n`,(0,n.jsx)(e.li,{children:\"Base case is when there are no more items left to be processed and an empty array is returned.\"}),`\n`,(0,n.jsx)(e.li,{children:\"Finally, merge the results from Step 1 and the mapped results from the remaining items in Step 2 and return it.\"}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"We have to take note of making the recursive call to \",(0,n.jsx)(e.code,{children:\"mapAsyncLimit\"}),\" only after Step 1 has concluded, otherwise we are exceeding the required concurrency limit and there will be no difference from \",(0,n.jsx)(e.code,{children:\"mapAsync\"}),\".\"]}),`\n`,(0,n.jsx)(r,{languages:{jsx:m,tsx:u}}),`\n`,(0,n.jsxs)(e.p,{children:[\"The downside of this solution (as with all recursive approaches) is that there's a limit to the recursion stack. However, there's a more modern and cleaner solution using \",(0,n.jsx)(e.code,{children:\"async\"}),\"/\",(0,n.jsx)(e.code,{children:\"await\"}),\".\"]}),`\n`,(0,n.jsxs)(e.h3,{children:[\"Approach 3: Chunks with \",(0,n.jsx)(e.code,{children:\"async\"}),\"/\",(0,n.jsx)(e.code,{children:\"await\"})]}),`\n`,(0,n.jsxs)(e.p,{children:[\"With \",(0,n.jsx)(e.code,{children:\"async\"}),\"/\",(0,n.jsx)(e.code,{children:\"await\"}),\", the idea stays the same, but it's easier to write sequential \",(0,n.jsx)(e.code,{children:\"async\"}),\" code by slicing the array into chunks of \",(0,n.jsx)(e.code,{children:\"size\"}),\" and \",(0,n.jsx)(e.code,{children:\"await\"}),\"-ing each chunk within a for-loop.\"]}),`\n`,(0,n.jsx)(r,{children:p}),`\n`,(0,n.jsx)(e.h3,{children:\"Approach 4: Chunkless (max concurrency)\"}),`\n`,(0,n.jsx)(e.p,{children:\"The previous approaches have a huge downside, that is there is some idleness and the available upper concurrency limit is not always fully-utilized.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Imagine there are 7 items to be mapped, each requiring different durations. The diagram below shows the relative difference in the duration depending on the mapping approach taken.\"}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{src:\"/img/questions/map-async-limit/map-async-limit.png\",alt:\"Map async limit\"})}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Sequential\"}),\": A sequential (one at a time) approach will certainly stay within the concurrency limit, but is extremely slow and not utilizing the fact that we can have concurrent async tasks.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Chunks\"}),\": The chunks approach improves the concurrency but it waits for all items in the current chunk to be completed before moving on to the next. If there's a task that is much slower than the rest, there will be idle cycles and the available limit is not fully-utilized.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Chunkless\"}),\": The most efficient approach is to immediately start processing the next item when an item is completed. This ensures that there are always \",(0,n.jsx)(e.code,{children:\"size\"}),\" ongoing async tasks (when there are unprocessed items) and the available limit is fully-utilized.\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Like in the custom implementation of \",(0,n.jsx)(e.code,{children:\"Promise.all\"}),\", we can track the number of resolved items and \",(0,n.jsx)(e.code,{children:\"resolve()\"}),\" with the mapped results when every item has been processed.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"The idea here is to define a function \",(0,n.jsx)(e.code,{children:\"processItem\"}),\" that takes in an index and processes the item at that index, adding the result to the final mapped \",(0,n.jsx)(e.code,{children:\"results\"}),\" array when that item is complete. \",(0,n.jsx)(e.code,{children:\"processItem\"}),\" is a recursive function that will call itself with the index of the next item to be processed.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"To do that, we need to track the index of the next item to be processed as \",(0,n.jsx)(e.code,{children:\"nextIndex\"}),\". Whenever an item starts processing, \",(0,n.jsx)(e.code,{children:\"nextIndex\"}),\" is incremented. When an item has been processed, we can process the item at \",(0,n.jsx)(e.code,{children:\"nextIndex\"}),\" as the next step. This ensures there are always \",(0,n.jsx)(e.code,{children:\"size\"}),\" ongoing async tasks (while there are remaining unprocessed items) and it's always at the limit.\"]}),`\n`,(0,n.jsx)(e.p,{children:\"This goes on until all the items have been processed or one of the items have been rejected/errored.\"}),`\n`,(0,n.jsx)(r,{children:f}),`\n`,(0,n.jsxs)(e.p,{children:[\"The following approach uses \",(0,n.jsx)(e.code,{children:\"async\"}),\"/\",(0,n.jsx)(e.code,{children:\"await\"}),\" for the internal recursive function:\"]}),`\n`,(0,n.jsx)(r,{children:y})]})}function q(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,Object.assign({},t,{children:(0,n.jsx)(b,t)})):b(t)}var M=q;return z(S);})();\n;return Component;",
  "workspace": {
    "main": "/src/map-async-limit.ts",
    "run": "/src/map-async-limit.run.test.ts",
    "submit": "/src/map-async-limit.submit.test.ts"
  }
}